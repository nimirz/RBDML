{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Climate Data from Google Earth Engine\n",
    "\n",
    "To investigate how climate impacts human rodent-borne disease cases, we must obtain historical climate data for a variety of countries. The climate parameters we are interested in and the datasets we are sourcing from:\n",
    "\n",
    "Parameters used from other paper\n",
    "Tmean, minimum daily air temperature—Tmin, and maximum daily air temperature—Tmax (all temperatures are the monthly averages of the corresponding daily values, in 2 m height above ground, in °C); total precipitation in mm—Pr, total sunshine duration in hours—SD, mean monthly soil temperature in 5 cm depth under uncovered typical soil of location in °C—ST, and soil moisture under grass and sandy loam in percent plant useable water—SM. \n",
    "\n",
    "WorldClim for historical data? https://developers.google.com/earth-engine/datasets/catalog/UCSB-CHG_CHIRPS_PENTAD\n",
    "\n",
    "\n",
    "|Parameter|Dataset|Resolution|Details|Reference|\n",
    "|----|----|----|----|---|\n",
    "|Mean daily land surface temperature|MODIS MOD11A1 v061|1 km|daily temperature|https://doi.org/10.5067/MODIS/MOD11A1.061|\n",
    "|Monthly total precipitation|CHIRPS 2.0|0.05 degrees (5566 meters)|Climate hazards group InfraRed Precip wth station data. Each image represents a pentad (5 days).|https://developers.google.com/earth-engine/datasets/catalog/UCSB-CHG_CHIRPS_PENTAD\n",
    "|Precipitation|IMERG GPM v6|11132 meters|Precip observations every 3 hours|https://doi.org/10.5067/GPM/IMERG/3B-HH-L/06|\n",
    "|Soil Temperature|\n",
    "|Enhaced vegetation index|MODIS Terra Vegetation 16-Day Global 1km|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import ee\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Earth Engine. If first time using GEE in notebook setup, make sure that a project has been created and your account as been added, then run the authenticate command to link your account. Additionally, set up the working directory. Enter the authorization code you receive from google into the box. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/cloud-platform%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=h4P1P6a_OFJEUKInBFkk8Rfw9nwVUEYnfwrXeGkRAAY&tc=-3QeVd_MP9q71KO8ghDjciAYL7iLHs1p8WUtcSRPobw&cc=lBwrimVm8Y2dcHD1OYTcucHU_CBLStQ4GUd7tpBP6K4>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/cloud-platform%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=h4P1P6a_OFJEUKInBFkk8Rfw9nwVUEYnfwrXeGkRAAY&tc=-3QeVd_MP9q71KO8ghDjciAYL7iLHs1p8WUtcSRPobw&cc=lBwrimVm8Y2dcHD1OYTcucHU_CBLStQ4GUd7tpBP6K4</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "ee.Authenticate()\n",
    "ee.Initialize()\n",
    "\n",
    "wd = '~/Dropbox/RBDML'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Regions of Interest\n",
    "\n",
    "The case data for hantavirus and lassa fever only focus on the following countries based on the listed criteria. We will be downloading gridded raster for the climate parameters \n",
    "\n",
    "Country inclusion criteria:\n",
    "- More than 10 cases in one month\n",
    "- More than 300 total cases across all years\n",
    "\n",
    "Countries included:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>minyear</th>\n",
       "      <th>maxyear</th>\n",
       "      <th>max_monthly_cases</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2008</td>\n",
       "      <td>2021</td>\n",
       "      <td>46</td>\n",
       "      <td>1134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bolivia</td>\n",
       "      <td>2010</td>\n",
       "      <td>2023</td>\n",
       "      <td>219</td>\n",
       "      <td>9276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>2001</td>\n",
       "      <td>2020</td>\n",
       "      <td>65</td>\n",
       "      <td>544071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chile</td>\n",
       "      <td>1995</td>\n",
       "      <td>2022</td>\n",
       "      <td>18</td>\n",
       "      <td>9055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>China</td>\n",
       "      <td>2004</td>\n",
       "      <td>2023</td>\n",
       "      <td>4189</td>\n",
       "      <td>228738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  minyear  maxyear  max_monthly_cases  total_cases\n",
       "0  Austria     2008     2021                 46         1134\n",
       "1  Bolivia     2010     2023                219         9276\n",
       "2   Brazil     2001     2020                 65       544071\n",
       "3    Chile     1995     2022                 18         9055\n",
       "4    China     2004     2023               4189       228738"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import csv with regions and date ranges\n",
    "df = pd.read_csv('../../data/processed/country_list.csv')\n",
    "#df.set_index('country', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will be using prior climate data to inform predictions, we will climate data from up 2 years prior and will subtract 2 years from the minimum year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.minyear = df.minyear - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Obtain Land Surface Temperature (LST)\n",
    "\n",
    "First we will define the functions needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def sumDailyPrecip(collection, date):\n",
    "    '''\n",
    "        #Calculate the sum for the day\n",
    "    '''\n",
    "    date = ee.Date(date)\n",
    "    return (collection\n",
    "            .filter(ee.Filter.date(date.getRange('day')))\n",
    "            .sum()\n",
    "            .set(\"day\", date.format(\"DD\"))\n",
    "            .set(\"month\", date.format(\"MM\"))\n",
    "            .set(\"year\", date.format(\"YYYY\"))\n",
    "            .set(\"system:index\", ee.String(year).cat('-').cat(month).cat('-').cat(day)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleAndMask(img):\n",
    "    '''\n",
    "        Takes in an image and returns the the day LST in celcius, masked by quality.\n",
    "    '''\n",
    "    # Select the QA bands\n",
    "    qc = img.select('QC_Day')\n",
    "\n",
    "    # Create masks:\n",
    "    qa_flag_mask = qc.bitwiseAnd(0b11).lt(2) # Bits 0-1 <= 1; good or other quality\n",
    "    data_quality_mask = qc.bitwiseAnd(0b1100).rightShift(2).eq(0) # Bits 2-3 = 0; good data quality\n",
    "\n",
    "    good_qc = qa_flag_mask.And(data_quality_mask)\n",
    "\n",
    "    return(img.select('LST_Day_1km')\n",
    "           .multiply(0.02) # convert from Kelvin\n",
    "           .subtract(273.15)\n",
    "           .updateMask(good_qc)\n",
    "           .copyProperties(img, ['system:time_start']))\n",
    "\n",
    "def eviMask(img):\n",
    "    '''\n",
    "        Takes in an image and returns the the day LST in celcius, masked by quality.\n",
    "    '''\n",
    "    # Select the QA bands\n",
    "    qc = img.select('SummaryQA')\n",
    "\n",
    "    # Create masks:\n",
    "    qa_flag_mask = qc.bitwiseAnd(1 << 0).eq(0) # left-shift: only looking at last bit -> if 0 good quality\n",
    "\n",
    "    return(img.select('EVI')\n",
    "           .multiply(0.0001)\n",
    "           .updateMask(qa_flag_mask)\n",
    "           .copyProperties(img, ['system:time_start']))\n",
    "\n",
    "\n",
    "\n",
    "def sumDailyPrecip(collection, date):\n",
    "    '''\n",
    "        Calculate the sum for the day\n",
    "    '''\n",
    "    date = ee.Date(date)\n",
    "    # Filter the collection for the given date\n",
    "    filtered_collection = collection.filterDate(date, date.advance(1, 'day'))\n",
    "    # Calculate the sum for the day\n",
    "    daily_sum = filtered_collection.sum()\n",
    "    # Get day, month, and year\n",
    "    day = date.format(\"DD\")\n",
    "    month = date.format(\"MM\")\n",
    "    year = date.format(\"YYYY\")\n",
    "    # Set properties\n",
    "    return daily_sum.set({\n",
    "        \"day\": day,\n",
    "        \"month\": month,\n",
    "        \"year\": year,\n",
    "        \"system:index\": ee.String(year).cat('-').cat(month).cat('-').cat(day)\n",
    "    })\n",
    "\n",
    "\n",
    "def sumMonthlyComposite(collection, date):\n",
    "    '''\n",
    "        Calculate the sum for a month for an image.\n",
    "    '''\n",
    "    date = ee.Date(date)\n",
    "    return (collection\n",
    "            .filterDate(date, date.advance(1, 'month'))\n",
    "            .sum()\n",
    "            .set(\"month\", date.format(\"MM\"))\n",
    "            .set(\"year\", date.format(\"YYYY\"))\n",
    "            .set(\"system:index\", date.format(\"MM-YYYY\")))\n",
    "\n",
    "def meanMonthlyComposite(collection, date):\n",
    "    '''\n",
    "        Calculate the mean for a month for an image.\n",
    "    '''\n",
    "    date = ee.Date(date)\n",
    "    return (collection\n",
    "            .filterDate(date, date.advance(1, 'month'))\n",
    "            .mean()\n",
    "            .set(\"month\", date.format(\"MM\"))\n",
    "            .set(\"year\", date.format(\"YYYY\"))\n",
    "            .set(\"system:index\", date.format(\"MM-YYYY\")))\n",
    "\n",
    "\n",
    "def fcToDict(fc):\n",
    "  '''\n",
    "    Turns a feature collection into a dictionary. \n",
    "  '''\n",
    "  prop_names = fc.first().propertyNames()\n",
    "  prop_lists = fc.reduceColumns(\n",
    "      reducer=ee.Reducer.toList().repeat(prop_names.size()),\n",
    "      selectors=prop_names).get('list')\n",
    "\n",
    "  return ee.Dictionary.fromLists(prop_names, prop_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to create a list of the countries we will be using and load image collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Collection for list of countries\n",
    "# Using the FAO GAUL Admin Layers: https://developers.google.com/earth-engine/datasets/catalog/FAO_GAUL_2015_level0#table-schema\n",
    "# Export for admin 1 level for all \n",
    "countries = ee.Filter.inList('ADM0_NAME', list(df['country'])[0]) # using FIPS country code\n",
    "regions = ee.FeatureCollection('FAO/GAUL/2015/level1').filter(countries)\n",
    "\n",
    "# Dates required\n",
    "#year = '2012'\n",
    "#start = ee.Date('2012-01-01')\n",
    "#end = ee.Date('2013-01-01')\n",
    "\n",
    "# Image collection\n",
    "# Import the MODIS land surface temperature collection.\n",
    "#collection = ee.ImageCollection('MODIS/006/MOD11A1').filterDate(start,end).map(scaleAndMask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export daily LST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting task for Austria\n",
      "Starting task for Brazil\n",
      "Starting task for Chile\n",
      "Starting task for China\n",
      "Starting task for Finland\n",
      "Starting task for France\n",
      "Starting task for Germany\n",
      "Starting task for Nigeria\n",
      "Starting task for Norway\n",
      "Starting task for Slovakia\n",
      "Starting task for Slovenia\n",
      "Starting task for Sweden\n",
      "Starting task for United States of America\n"
     ]
    }
   ],
   "source": [
    "collection = ee.ImageCollection('MODIS/006/MOD11A1').map(scaleAndMask)\n",
    "collection_min_date = ee.Date(collection.aggregate_min('system:time_start'))\n",
    "collection_max_date = ee.Date(collection.aggregate_max('system:time_start'))\n",
    "\n",
    "for country in df['country']:\n",
    "    # define date range\n",
    "    start = ee.Date.fromYMD(df.loc[df['country'] == country, 'minyear'].item(), 1, 1)\n",
    "    end = ee.Date.fromYMD(df.loc[df['country'] == country, 'maxyear'].item(), 12, 31)\n",
    "\n",
    "    # if dates are outside of collection range\n",
    "    if start.difference(collection_min_date, 'days').getInfo() < 0: start = collection_min_date\n",
    "    if end.difference(collection_max_date, 'days').getInfo() > 0: end = collection_max_date\n",
    "    \n",
    "    region = ee.FeatureCollection('FAO/GAUL/2015/level1').filter(ee.Filter.eq('ADM0_NAME', country))\n",
    "    daily_lst_filtered = collection.filterDate(start, end)\n",
    "\n",
    "    # Determine mean for admin region\n",
    "    daily_lst = daily_lst_filtered.map(lambda image: image.reduceRegions(\n",
    "        reducer=ee.Reducer.mean().setOutputs(['mean_lst']),\n",
    "        collection=region,\n",
    "        scale=1000\n",
    "    )).flatten()\n",
    "\n",
    "    # Export the FeatureCollection to Google Drive as a CSV file\n",
    "    task = ee.batch.Export.table.toDrive(\n",
    "        collection=daily_lst,\n",
    "        description=country+'_DailyLST',\n",
    "        fileFormat='CSV',\n",
    "        folder='test',\n",
    "        selectors=['system:index', 'ADM0_CODE',\t'ADM0_NAME', 'ADM1_CODE', 'ADM1_NAME', 'mean_lst']\n",
    "    )\n",
    "\n",
    "    # Start the export task\n",
    "    task.start()\n",
    "    print('Starting task for '+ country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finland at 2nd admin unit so do more detailed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting task for Finland\n"
     ]
    }
   ],
   "source": [
    "collection = ee.ImageCollection('MODIS/006/MOD11A1').map(scaleAndMask)\n",
    "collection_min_date = ee.Date(collection.aggregate_min('system:time_start'))\n",
    "collection_max_date = ee.Date(collection.aggregate_max('system:time_start'))\n",
    "\n",
    "for country in ['Finland']:\n",
    "    # define date range\n",
    "    start = ee.Date.fromYMD(df.loc[df['country'] == country, 'minyear'].item(), 1, 1)\n",
    "    end = ee.Date.fromYMD(df.loc[df['country'] == country, 'maxyear'].item(), 12, 31)\n",
    "\n",
    "    # if dates are outside of collection range\n",
    "    if start.difference(collection_min_date, 'days').getInfo() < 0: start = collection_min_date\n",
    "    if end.difference(collection_max_date, 'days').getInfo() > 0: end = collection_max_date\n",
    "    \n",
    "    region = ee.FeatureCollection('FAO/GAUL/2015/level2').filter(ee.Filter.eq('ADM0_NAME', country))\n",
    "    daily_lst_filtered = collection.filterDate(start, end)\n",
    "\n",
    "    # Determine mean for admin region\n",
    "    daily_lst = daily_lst_filtered.map(lambda image: image.reduceRegions(\n",
    "        reducer=ee.Reducer.mean().setOutputs(['mean_lst']),\n",
    "        collection=region,\n",
    "        scale=1000\n",
    "    )).flatten()\n",
    "\n",
    "    # Export the FeatureCollection to Google Drive as a CSV file\n",
    "    task = ee.batch.Export.table.toDrive(\n",
    "        collection=daily_lst,\n",
    "        description=country+'_DailyLST',\n",
    "        fileFormat='CSV',\n",
    "        folder='GEE/Temperature/',\n",
    "        selectors=['system:index', 'ADM0_CODE',\t'ADM0_NAME', 'ADM1_CODE', 'ADM1_NAME', 'ADM2_CODE', 'ADM2_NAME', 'mean_lst']\n",
    "    )\n",
    "\n",
    "    # Start the export task\n",
    "    task.start()\n",
    "    print('Starting task for '+ country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precipitation Data\n",
    "\n",
    "For CHIRPS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for Finland extends past dataset limit. Setting end date as \n",
      "Starting task for Finland\n",
      "Starting task for Norway\n",
      "Data for Sweden extends past dataset limit. Setting end date as \n",
      "Starting task for Sweden\n"
     ]
    }
   ],
   "source": [
    "collection = ee.ImageCollection('UCSB-CHG/CHIRPS/DAILY')\n",
    "collection_min_date = ee.Date(collection.aggregate_min('system:time_start'))\n",
    "collection_max_date = ee.Date(collection.aggregate_max('system:time_start'))\n",
    "\n",
    "for country in df['country']:\n",
    "    # define date range\n",
    "    start = ee.Date.fromYMD(df.loc[df['country'] == country, 'minyear'].item(), 1, 1)\n",
    "    end = ee.Date.fromYMD(df.loc[df['country'] == country, 'maxyear'].item(), 12, 31)\n",
    "\n",
    "    # if dates are outside of collection range\n",
    "    if start.difference(collection_min_date, 'days').getInfo() < 0: \n",
    "        print(\"Data for \"+country+\" starts earlier than dataset.\")\n",
    "        start = collection_min_date\n",
    "    if end.difference(collection_max_date, 'days').getInfo() > 0: \n",
    "        print(\"Data for \"+country+\" extends past dataset limit.\")\n",
    "        end = collection_max_date\n",
    "    \n",
    "    region = ee.FeatureCollection('FAO/GAUL/2015/level2').filter(ee.Filter.eq('ADM0_NAME', country))\n",
    "    filtered_collection = collection.filterDate(start, end)\n",
    "\n",
    "    # determine mean for admin region\n",
    "    daily_precip = filtered_collection.map(lambda image: image.reduceRegions(\n",
    "        reducer=ee.Reducer.mean().setOutputs(['precipitation']),\n",
    "        collection=region,\n",
    "        scale=5000\n",
    "    )).flatten()\n",
    "\n",
    "    # Export the FeatureCollection to Google Drive as a CSV file\n",
    "    task = ee.batch.Export.table.toDrive(\n",
    "        collection=daily_precip,\n",
    "        description=country+'_DailyCHIRPSPrecip',\n",
    "        fileFormat='CSV',\n",
    "        folder='test',\n",
    "        selectors=['system:index', 'ADM0_CODE',\t'ADM0_NAME', 'ADM1_CODE', 'ADM1_NAME', 'precipitation']\n",
    "    )\n",
    "\n",
    "    # Start the export task\n",
    "    task.start()\n",
    "    print('Starting task for '+ country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For daily IMERG data (https://developers.google.com/earth-engine/datasets/catalog/NASA_GPM_L3_IMERG_V06#description)\n",
    "\n",
    "\n",
    "PrecipitationCal: Multi-satellite precipitation estimate with gauge calibration (recommended for general use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ee.image.Image at 0x28945c9d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_collection.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m end \u001b[38;5;241m=\u001b[39m ee\u001b[38;5;241m.\u001b[39mDate\u001b[38;5;241m.\u001b[39mfromYMD(\u001b[38;5;241m2012\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# if dates are outside of collection range\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mstart\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdifference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection_min_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdays\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m: \n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData for \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mcountry\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m starts earlier than dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m     start \u001b[38;5;241m=\u001b[39m collection_min_date\n",
      "File \u001b[0;32m~/miniconda3/envs/rbdml/lib/python3.11/site-packages/ee/computedobject.py:107\u001b[0m, in \u001b[0;36mComputedObject.getInfo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetInfo\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Any]:\n\u001b[1;32m    102\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Fetch and return information about this object.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    The object can evaluate to anything.\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomputeValue\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rbdml/lib/python3.11/site-packages/ee/data.py:1107\u001b[0m, in \u001b[0;36mcomputeValue\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1104\u001b[0m body \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpression\u001b[39m\u001b[38;5;124m'\u001b[39m: serializer\u001b[38;5;241m.\u001b[39mencode(obj, for_cloud_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)}\n\u001b[1;32m   1105\u001b[0m _maybe_populate_workload_tag(body)\n\u001b[0;32m-> 1107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_execute_cloud_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_get_cloud_projects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_get_projects_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprettyPrint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/rbdml/lib/python3.11/site-packages/ee/data.py:402\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Executes a Cloud API call and translates errors to EEExceptions.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \n\u001b[1;32m    390\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;124;03m  EEException if the call fails.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 402\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    404\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m _translate_cloud_exception(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/rbdml/lib/python3.11/site-packages/googleapiclient/_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m positional_parameters_enforcement \u001b[38;5;241m==\u001b[39m POSITIONAL_WARNING:\n\u001b[1;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rbdml/lib/python3.11/site-packages/googleapiclient/http.py:923\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbody))\n\u001b[1;32m    922\u001b[0m \u001b[38;5;66;03m# Handle retries for server-side errors.\u001b[39;00m\n\u001b[0;32m--> 923\u001b[0m resp, content \u001b[38;5;241m=\u001b[39m \u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrequest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_callbacks:\n\u001b[1;32m    936\u001b[0m     callback(resp)\n",
      "File \u001b[0;32m~/miniconda3/envs/rbdml/lib/python3.11/site-packages/googleapiclient/http.py:191\u001b[0m, in \u001b[0;36m_retry_request\u001b[0;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m     resp, content \u001b[38;5;241m=\u001b[39m \u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# Retry on SSL errors and socket timeout errors.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _ssl_SSLError \u001b[38;5;28;01mas\u001b[39;00m ssl_error:\n",
      "File \u001b[0;32m~/miniconda3/envs/rbdml/lib/python3.11/site-packages/google_auth_httplib2.py:218\u001b[0m, in \u001b[0;36mAuthorizedHttp.request\u001b[0;34m(self, uri, method, body, headers, redirections, connection_type, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     body_stream_position \u001b[38;5;241m=\u001b[39m body\u001b[38;5;241m.\u001b[39mtell()\n\u001b[1;32m    217\u001b[0m \u001b[38;5;66;03m# Make the request.\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m response, content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mredirections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mredirections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnection_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# If the response indicated that the credentials needed to be\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m# refreshed, then refresh the credentials and re-attempt the\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# request.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# A stored token may expire between the time it is retrieved and\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# the time the request is made, so we may need to try twice.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    234\u001b[0m     response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_refresh_status_codes\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m _credential_refresh_attempt \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_refresh_attempts\n\u001b[1;32m    236\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/rbdml/lib/python3.11/site-packages/ee/_cloud_api_utils.py:70\u001b[0m, in \u001b[0;36m_Http.request\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m redirections  \u001b[38;5;66;03m# Ignored\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m   \u001b[38;5;66;03m# googleapiclient is expecting an httplib2 object, and doesn't include\u001b[39;00m\n\u001b[1;32m     67\u001b[0m   \u001b[38;5;66;03m# requests error in the list of transient errors. Therefore, transient\u001b[39;00m\n\u001b[1;32m     68\u001b[0m   \u001b[38;5;66;03m# requests errors should be converted to kinds that googleapiclient\u001b[39;00m\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;66;03m# consider transient.\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mConnectionError \u001b[38;5;28;01mas\u001b[39;00m connection_error:\n\u001b[1;32m     74\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(connection_error) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconnection_error\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rbdml/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/rbdml/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda3/envs/rbdml/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/miniconda3/envs/rbdml/lib/python3.11/site-packages/urllib3/connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    809\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rbdml/lib/python3.11/site-packages/urllib3/connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/rbdml/lib/python3.11/site-packages/urllib3/connection.py:466\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    465\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/miniconda3/envs/rbdml/lib/python3.11/http/client.py:1386\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1385\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1386\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1388\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/rbdml/lib/python3.11/http/client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rbdml/lib/python3.11/http/client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/rbdml/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rbdml/lib/python3.11/ssl.py:1315\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1312\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1313\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1314\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/rbdml/lib/python3.11/ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "collection = ee.ImageCollection(\"NASA/GPM_L3/IMERG_V06\")\n",
    "collection_min_date = ee.Date(collection.aggregate_min('system:time_start'))\n",
    "collection_max_date = ee.Date(collection.aggregate_max('system:time_start'))\n",
    "collection = collection.select('precipitationCal')\n",
    "\n",
    "for country in df['country'][1]:\n",
    "    # define date range\n",
    "    #start = ee.Date.fromYMD(df.loc[df['country'] == country, 'minyear'].item(), 1, 1)\n",
    "    #end = ee.Date.fromYMD(df.loc[df['country'] == country, 'maxyear'].item(), 12, 31)\n",
    "    start = ee.Date.fromYMD(2012, 1, 1)\n",
    "    end = ee.Date.fromYMD(2012, 1, 5)\n",
    "\n",
    "    # if dates are outside of collection range\n",
    "    if start.difference(collection_min_date, 'days').getInfo() < 0: \n",
    "        print(\"Data for \"+country+\" starts earlier than dataset.\")\n",
    "        start = collection_min_date\n",
    "    if end.difference(collection_max_date, 'days').getInfo() > 0: \n",
    "        print(\"Data for \"+country+\" extends past dataset limit.\")\n",
    "        end = collection_max_date\n",
    "\n",
    "    region = ee.FeatureCollection('FAO/GAUL/2015/level1').filter(ee.Filter.eq('ADM0_NAME', country))\n",
    "    filtered_collection = collection.filterDate(start, end)\n",
    "\n",
    "    n_days = end.difference(start, 'day').subtract(1)\n",
    "    days = ee.List.sequence(0, n_days).map(lambda n : start.advance(n, 'day'))\n",
    "    daily_collection = ee.ImageCollection(days.map(lambda date: sumDailyPrecip(filtered_collection, date)))\n",
    "\n",
    "    daily_precip = daily_collection.map(lambda image: image.reduceRegions(\n",
    "        reducer=ee.Reducer.mean().setOutputs(['precipitation']),\n",
    "        collection=region,\n",
    "        scale=10000\n",
    "    ))\n",
    "\n",
    "    # Define a function to transfer properties from the original image to the features\n",
    "    def transferProperties(feature):\n",
    "        # Get the corresponding image\n",
    "        image = ee.Image(feature.get('image'))\n",
    "        # Transfer desired properties from the image to the feature\n",
    "        return feature.copyProperties(image, ['day', 'month', 'year'])\n",
    "\n",
    "    # Map the transferProperties function over the daily_precip feature collection\n",
    "    transferred_precip = daily_precip.map(transferProperties).flatten()\n",
    "\n",
    "    # Export the FeatureCollection to Google Drive as a CSV file\n",
    "    task = ee.batch.Export.table.toDrive(\n",
    "        collection=transferred_precip,\n",
    "        description=country+'_sum_GPM',\n",
    "        fileFormat='CSV',\n",
    "        folder='GEE_data/precip_daily',\n",
    "        selectors=['system:index', 'day', 'month', 'year', 'ADM0_CODE',\t'ADM0_NAME', 'ADM1_CODE', 'ADM1_NAME', 'precipitation']\n",
    "    )\n",
    "\n",
    "    # Start the export task\n",
    "    task.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying monthly aggregate from here: https://developers.google.com/earth-engine/datasets/catalog/ECMWF_ERA5_LAND_MONTHLY_AGGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for China extends past dataset limit.\n",
      "Data for Finland extends past dataset limit.\n",
      "Data for Germany extends past dataset limit.\n",
      "Data for Nigeria extends past dataset limit.\n",
      "Data for Sweden extends past dataset limit.\n"
     ]
    }
   ],
   "source": [
    "collection = ee.ImageCollection(\"ECMWF/ERA5_LAND/MONTHLY_AGGR\")\n",
    "collection_min_date = ee.Date(collection.aggregate_min('system:time_start'))\n",
    "collection_max_date = ee.Date(collection.aggregate_max('system:time_start'))\n",
    "collection = collection.select('total_precipitation_sum')\n",
    "\n",
    "for country in df['country']:\n",
    "    # define date range\n",
    "    start = ee.Date.fromYMD(df.loc[df['country'] == country, 'minyear'].item(), 1, 1)\n",
    "    end = ee.Date.fromYMD(df.loc[df['country'] == country, 'maxyear'].item(), 12, 31)\n",
    "\n",
    "    # if dates are outside of collection range\n",
    "    if start.difference(collection_min_date, 'days').getInfo() < 0: \n",
    "        print(\"Data for \"+country+\" starts earlier than dataset.\")\n",
    "        start = collection_min_date\n",
    "    if end.difference(collection_max_date, 'days').getInfo() > 0: \n",
    "        print(\"Data for \"+country+\" extends past dataset limit.\")\n",
    "        end = collection_max_date\n",
    "    \n",
    "    region = ee.FeatureCollection('FAO/GAUL/2015/level1').filter(ee.Filter.eq('ADM0_NAME', country))\n",
    "    filtered_collection = collection.filterDate(start, end)\n",
    "\n",
    "   # n_days = end.difference(start, 'day').subtract(1)\n",
    "   # days = ee.List.sequence(0, n_days).map(lambda n : start.advance(n, 'day'))\n",
    "   # daily_collection = ee.ImageCollection(days.map(lambda date: sumDailyPrecip(filtered_collection, date)))\n",
    "\n",
    "    # determine mean for admin region\n",
    "    monthly_precip = collection.map(lambda image: image.reduceRegions(\n",
    "        reducer=ee.Reducer.mean().setOutputs(['precipitation_m']),\n",
    "        collection=region,\n",
    "        scale=10000\n",
    "    )).flatten()\n",
    "\n",
    "    # Export the FeatureCollection to Google Drive as a CSV file\n",
    "    task = ee.batch.Export.table.toDrive(\n",
    "        collection=daily_precip,\n",
    "        description=country+'_monthly_GPM',\n",
    "        fileFormat='CSV',\n",
    "        folder='GEE_data/precip_monthly',\n",
    "        selectors=['system:index', 'ADM0_CODE',\t'ADM0_NAME', 'ADM1_CODE', 'ADM1_NAME', 'precipitation_m']\n",
    "    )\n",
    "\n",
    "    # Start the export task\n",
    "    task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = img.get('HQ_Precipitation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ee.Image({\n",
      "  \"functionInvocationValue\": {\n",
      "    \"functionName\": \"Collection.first\",\n",
      "    \"arguments\": {\n",
      "      \"collection\": {\n",
      "        \"functionInvocationValue\": {\n",
      "          \"functionName\": \"ImageCollection.load\",\n",
      "          \"arguments\": {\n",
      "            \"id\": {\n",
      "              \"constantValue\": \"UCSB-CHG/CHIRPS/DAILY\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "collection = ee.ImageCollection('UCSB-CHG/CHIRPS/DAILY')\n",
    "print(collection.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting task for Austria\n",
      "Starting task for Brazil\n",
      "Data for Chile starts earlier than dataset.\n",
      "Starting task for Chile\n",
      "Starting task for China\n",
      "Data for Finland starts earlier than dataset.\n",
      "Starting task for Finland\n",
      "Starting task for France\n",
      "Starting task for Germany\n",
      "Starting task for Nigeria\n",
      "Starting task for Norway\n",
      "Starting task for Slovakia\n",
      "Starting task for Slovenia\n",
      "Starting task for Sweden\n",
      "Data for United States of America starts earlier than dataset.\n",
      "Starting task for United States of America\n"
     ]
    }
   ],
   "source": [
    "collection = ee.ImageCollection(\"NASA/GPM_L3/IMERG_V06\")\n",
    "collection_min_date = ee.Date(collection.aggregate_min('system:time_start'))\n",
    "collection_max_date = ee.Date(collection.aggregate_max('system:time_start'))\n",
    "collection = collection.select('precipitationCal')\n",
    "\n",
    "for country in df['country']:\n",
    "    # define date range\n",
    "    start = ee.Date.fromYMD(df.loc[df['country'] == country, 'minyear'].item(), 1, 1)\n",
    "    end = ee.Date.fromYMD(df.loc[df['country'] == country, 'maxyear'].item(), 12, 31)\n",
    "\n",
    "    # if dates are outside of collection range\n",
    "    if start.difference(collection_min_date, 'days').getInfo() < 0: \n",
    "        print(\"Data for \"+country+\" starts earlier than dataset.\")\n",
    "        start = collection_min_date\n",
    "    if end.difference(collection_max_date, 'days').getInfo() > 0: \n",
    "        print(\"Data for \"+country+\" extends past dataset limit.\")\n",
    "        end = collection_max_date\n",
    "    \n",
    "    region = ee.FeatureCollection('FAO/GAUL/2015/level1').filter(ee.Filter.eq('ADM0_NAME', country))\n",
    "    filtered_collection = collection.filterDate(start, end)\n",
    "\n",
    "    n_days = end.difference(start, 'day').subtract(1)\n",
    "    days = ee.List.sequence(0, n_days).map(lambda n : start.advance(n, 'day'))\n",
    "    daily_collection = ee.ImageCollection(days.map(lambda date: sumDailyPrecip(filtered_collection, date)))\n",
    "\n",
    "    # determine mean for admin region\n",
    "    daily_precip = daily_collection.map(lambda image: image.reduceRegions(\n",
    "        reducer=ee.Reducer.mean().setOutputs(['precipitation']),\n",
    "        collection=region,\n",
    "        scale=10000\n",
    "    )).flatten()\n",
    "\n",
    "    # Export the FeatureCollection to Google Drive as a CSV file\n",
    "    task = ee.batch.Export.table.toDrive(\n",
    "        collection=daily_precip,\n",
    "        description=country+'_GPM',\n",
    "        fileFormat='CSV',\n",
    "        folder='GEE_data/precip',\n",
    "        selectors=['system:index', 'ADM0_CODE',\t'ADM0_NAME', 'ADM1_CODE', 'ADM1_NAME', 'precipitation']\n",
    "    )\n",
    "\n",
    "    # Start the export task\n",
    "    task.start()\n",
    "    print('Starting task for '+ country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODIS EVI DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for Finland starts earlier than dataset.\n",
      "Data for Finland extends past dataset limit.\n",
      "Starting task for Finland\n"
     ]
    }
   ],
   "source": [
    "collection = ee.ImageCollection(\"MODIS/061/MOD13A2\")\n",
    "collection_min_date = ee.Date(collection.aggregate_min('system:time_start'))\n",
    "collection_max_date = ee.Date(collection.aggregate_max('system:time_start'))\n",
    "\n",
    "#for country in ['Finland']:\n",
    "country = 'Finland'\n",
    "# define date range\n",
    "start = ee.Date.fromYMD(df.loc[df['country'] == country, 'minyear'].item(), 1, 1)\n",
    "end = ee.Date.fromYMD(df.loc[df['country'] == country, 'maxyear'].item(), 12, 31)\n",
    "\n",
    "# if dates are outside of collection range\n",
    "if start.difference(collection_min_date, 'days').getInfo() < 0: \n",
    "    print(\"Data for \"+country+\" starts earlier than dataset.\")\n",
    "    start = collection_min_date\n",
    "if end.difference(collection_max_date, 'days').getInfo() > 0: \n",
    "    print(\"Data for \"+country+\" extends past dataset limit.\")\n",
    "    end = collection_max_date\n",
    "\n",
    "region = ee.FeatureCollection('FAO/GAUL/2015/level2').filter(ee.Filter.eq('ADM0_NAME', country))\n",
    "filtered_collection = collection.filterDate(start, end)\n",
    "\n",
    "# determine mean for admin region\n",
    "daily_evi = filtered_collection.map(lambda image: image.reduceRegions(\n",
    "    reducer=ee.Reducer.mean().setOutputs(['EVI']),\n",
    "    collection=region,\n",
    "    scale=1000\n",
    ")).flatten()\n",
    "\n",
    "# Export the FeatureCollection to Google Drive as a CSV file\n",
    "task = ee.batch.Export.table.toDrive(\n",
    "    collection=daily_evi,\n",
    "    description=country+'_MonthlyModisEVI',\n",
    "    fileFormat='CSV',\n",
    "    folder='GEE_data',\n",
    "    selectors=['system:index', 'ADM0_CODE',\t'ADM0_NAME', 'ADM1_CODE', 'ADM1_NAME', 'ADM2_CODE', 'ADM2_NAME', 'EVI']\n",
    ")\n",
    "\n",
    "# Start the export task\n",
    "task.start()\n",
    "print('Starting task for '+ country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize downloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../data/climate/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dictionary for filename, value name, and unit\n",
    "\n",
    "climate_factors = {'DailyLST': ['mean_lst', 'celcius'],\n",
    "            'CHIRPSPrecip': ['precipitation', 'mm'],\n",
    "            'ModisEVI': ['EVI', 'spectral index']\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# get and combine files\n",
    "climate_df_list = []\n",
    "\n",
    "for key, value in climate_factors.items():\n",
    "    ext = key + '.csv'\n",
    "    files = [file for file in os.listdir(data_dir) if file.endswith(ext)]\n",
    "\n",
    "    df_list = []\n",
    "\n",
    "    # create dataframe list\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(data_dir, file_name)\n",
    "        df = pd.read_csv(file_path)  \n",
    "        df_list.append(df)\n",
    "\n",
    "    # combine to one dataframe\n",
    "    climate_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # rename column \n",
    "    climate_df.rename(columns={value[0]: 'value'}, inplace=True)\n",
    "    climate_df['measure'] = value[0]\n",
    "    climate_df['unit'] = value[1]\n",
    "\n",
    "    # fix date column\n",
    "    if key != 'CHIRPSPrecip':\n",
    "        climate_df[['year', 'month', 'day', 'index']] = climate_df['system:index'].str.split('_', expand=True)\n",
    "    else:\n",
    "        climate_df['year'] = climate_df['system:index'].str[:4]\n",
    "        climate_df['month'] = climate_df['system:index'].str[4:6]\n",
    "        climate_df['day'] = climate_df['system:index'].str[6:8]\n",
    "        climate_df['index'] = climate_df['system:index'].str[9:]\n",
    "\n",
    "    climate_df = climate_df.drop(columns=['system:index', 'index'])\n",
    "\n",
    "    # summarize by month\n",
    "    if key != 'CHIRPSPrecip':\n",
    "        climate_df = climate_df.groupby(['ADM0_NAME', 'ADM0_CODE', 'year', 'month', 'day']).agg({\n",
    "            'value': 'mean',\n",
    "         #   'ADM0_CODE': 'first',  \n",
    "          #  'ADM0_NAME': 'first',\n",
    "            'measure': 'first',\n",
    "            'unit': 'first',\n",
    "        }).reset_index()\n",
    "    else:\n",
    "        climate_df = climate_df.groupby(['ADM0_NAME', 'ADM0_CODE', 'year', 'month', 'day']).agg({\n",
    "            'value': 'sum',\n",
    "         #   'ADM0_CODE': 'first',  \n",
    "         #   'ADM0_NAME': 'first',\n",
    "            'measure': 'first',\n",
    "            'unit': 'first',\n",
    "        }).reset_index()\n",
    "\n",
    "    # add to list of dataframes\n",
    "    climate_df_list.append(climate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.concat(climate_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine dfs\n",
    "#df = pd.concat(climate_df_list, ignore_index=True)\n",
    "\n",
    "# change column order\n",
    "#df = df[['ADM0_NAME', 'ADM0_CODE', 'ADM1_NAME', 'ADM1_CODE', 'year', 'month', 'value', 'measure', 'unit']]\n",
    "\n",
    "# save\n",
    "out_df.to_csv(os.path.join(data_dir, '../processed/climate_data_daily.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rbdml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
